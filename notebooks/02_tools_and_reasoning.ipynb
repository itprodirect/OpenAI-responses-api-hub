{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# \ud83d\udee0\ufe0f Notebook 02: Tool Use and Agentic Reasoning with the Responses API\n\nThis lab shows how to register Python utilities as **tools** so the Responses API can plan, call, and explain its work."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## What you'll build\n- a lightweight calculator and repo file reader\n- a tool registry the model can invoke\n- a streaming tracer to watch planner/executor events"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Prerequisites\n1. `OPENAI_API_KEY` set in your `.env` (loaded automatically).\n2. `pip install -r requirements.txt`.\n3. Run this notebook from the repo root so file paths resolve."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from __future__ import annotations\n\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, List\n\nfrom openai import OpenAI\n\nfrom utils.openai_client import get_response\n\nclient = OpenAI()\nREPO_ROOT = Path('.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Define Python tools the model can call\nWe'll keep it simple: a calculator for basic arithmetic and a file reader for pulling short excerpts from this repository."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_calculator(operation: str, a: float, b: float) -> str:\n",
    "    \"\"\"Deterministic math helper that supports +, -, *, and /.\"\"\"\n",
    "    if operation not in {\"add\", \"subtract\", \"multiply\", \"divide\"}:\n",
    "        return f\"Unsupported operation: {operation}\"\n",
    "\n",
    "    if operation == \"add\":\n",
    "        value = a + b\n",
    "    elif operation == \"subtract\":\n",
    "        value = a - b\n",
    "    elif operation == \"multiply\":\n",
    "        value = a * b\n",
    "    else:\n",
    "        if b == 0:\n",
    "            return \"Cannot divide by zero.\"\n",
    "        value = a / b\n",
    "\n",
    "    return f\"{value:.4f}\"\n",
    "\n",
    "\n",
    "MAX_FILE_CHARS = 600\n",
    "\n",
    "\n",
    "def read_repo_file(relative_path: str) -> str:\n",
    "    \"\"\"Return a trimmed excerpt from a text file inside the repo.\"\"\"\n",
    "    repo_root = REPO_ROOT.resolve()\n",
    "    target = (repo_root / relative_path).resolve()\n",
    "\n",
    "    if not target.is_relative_to(repo_root):\n",
    "        return \"Only files within this repository can be read.\"\n",
    "\n",
    "    try:\n",
    "        text = target.read_text(encoding=\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        return f\"File {relative_path} was not found.\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"File {relative_path} is not plain text.\"\n",
    "\n",
    "    return text[:MAX_FILE_CHARS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "TOOLS: List[Dict[str, Any]] = [\n    {\n        'type': 'function',\n        'function': {\n            'name': 'basic_calculator',\n            'description': 'Perform deterministic arithmetic (add, subtract, multiply, divide).',\n            'parameters': {\n                'type': 'object',\n                'properties': {\n                    'operation': {\n                        'type': 'string',\n                        'enum': ['add', 'subtract', 'multiply', 'divide'],\n                        'description': 'Math operation to execute.',\n                    },\n                    'a': {\n                        'type': 'number',\n                        'description': 'First operand.',\n                    },\n                    'b': {\n                        'type': 'number',\n                        'description': 'Second operand.',\n                    },\n                },\n                'required': ['operation', 'a', 'b'],\n            },\n        },\n    },\n    {\n        'type': 'function',\n        'function': {\n            'name': 'read_repo_file',\n            'description': 'Read a short excerpt from a text file in this repository.',\n            'parameters': {\n                'type': 'object',\n                'properties': {\n                    'relative_path': {\n                        'type': 'string',\n                        'description': 'Path relative to the repo root (e.g., README.md).',\n                    }\n                },\n                'required': ['relative_path'],\n            },\n        },\n    },\n]\n\nPYTHON_TOOL_REGISTRY = {\n    'basic_calculator': basic_calculator,\n    'read_repo_file': read_repo_file,\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Register the tools in a helper call\nBecause `get_response` forwards `tools=` to the SDK, we can reuse the helper from Notebook 01 and immediately unlock richer behaviors."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "input_messages = [\n    {\n        'role': 'system',\n        'content': [{'type': 'text', 'text': 'You are a helpful planning assistant. Use tools when necessary and explain your steps.'}],\n    },\n    {\n        'role': 'user',\n        'content': [{'type': 'text', 'text': \"You can reason step by step. If you need repository context, call the file reader tool; for arithmetic, use the calculator. What is the difference between 2024 and 1998, and summarize the README intro in one sentence?\"}],\n    },\n]\n\nresponse_text = get_response(\n    input_messages,\n    model='gpt-4.1-mini',\n    tools=TOOLS,\n    reasoning={'effort': 'medium'},\n)\n\nprint(response_text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Watch the planner/executor trace with streaming events\nThe SDK's streaming interface emits events whenever the model reasons, plans, or calls a tool. Capturing those events turns the call into a narrated trace."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_with_trace(question: str) -> None:\n    stream = client.responses.stream(\n        model='gpt-4.1-mini',\n        input=[\n            {\n                'role': 'system',\n                'content': [\n                    {\n                        'type': 'text',\n                        'text': 'Be a careful planner. Think out loud, call tools when needed, and cite the tool outputs before answering.',\n                    }\n                ],\n            },\n            {\n                'role': 'user',\n                'content': [{'type': 'text', 'text': question}],\n            },\n        ],\n        tools=TOOLS,\n        reasoning={'effort': 'medium'},\n    )\n\n    with stream as events:\n        for event in events:\n            if event.type == 'response.output_text.delta':\n                print(f\"\ud83e\udde0 model reasoning: {event.delta}\")\n            elif event.type == 'response.tool_call.delta':\n                delta = event.delta\n                name = delta.get('name', 'tool')\n                args = delta.get('arguments')\n                print(f\"\ud83d\udd27 planning tool call -> {name}({args})\")\n            elif event.type == 'response.tool_call.completed':\n                call = event.tool_call\n                fn_name = call.function.name\n                parsed_args = json.loads(call.function.arguments or '{}')\n                tool_result = PYTHON_TOOL_REGISTRY.get(fn_name, lambda **_: 'Tool not found.')(**parsed_args)\n                print(f\"\u2705 executed {fn_name} with {parsed_args} => {tool_result}\")\n                events.send(\n                    {\n                        'type': 'response.tool_output',\n                        'tool_call_id': call.id,\n                        'output': tool_result,\n                    }\n                )\n            elif event.type == 'response.completed':\n                final = events.get_final_response()\n                text_blocks = []\n                for item in getattr(final, 'output', []):\n                    if getattr(item, 'type', '') == 'message':\n                        for content in getattr(item, 'content', []):\n                            if getattr(content, 'type', '') == 'output_text':\n                                text_blocks.append(content.text)\n                if text_blocks:\n                    print(\"\n\ud83c\udf89 Final answer:\n\" + '\n'.join(text_blocks))\n                break\n\nrun_with_trace('Use the calculator to compute 13.5 * 1.2 and quote a single sentence from README.md that mentions the project goals.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Reflection questions\n1. How would you add a tool that performs live web searches?\n2. What safeguards should you implement before letting the model read arbitrary files?\n3. Try swapping `gpt-4.1-mini` for a cheaper/faster model\u2014does the planner still pick the right tools?"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}