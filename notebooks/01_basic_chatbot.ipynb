{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0406aa11-15fc-4706-ae4f-53760bb18929",
   "metadata": {},
   "source": [
    "# ü§ñ Build Your First Basic Chatbot with the OpenAI Responses API\n",
    "\n",
    "Welcome! In this notebook, we're going to show you how to talk to a powerful AI model using **OpenAI's Responses API**.\n",
    "\n",
    "This will be like texting a super-smart assistant ‚Äî and we'll explain each step like you're 5 years old (ELI5 style).\n",
    "\n",
    "You'll learn:\n",
    "\n",
    "- üîë How to securely load your API key  \n",
    "- üì¨ How to send a message to the model  \n",
    "- üí¨ How to print out what it says back  \n",
    "\n",
    "Let‚Äôs get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d73be8-5a84-4b33-8d4c-aec7d320d68d",
   "metadata": {},
   "source": [
    "## üìä Models Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840375a1-9de2-405f-96da-a1ec5f2c3d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\user\\Desktop\\OpenAI-responses-api-hub\n",
      "sys.path[0]: C:\\Users\\user\\Desktop\\OpenAI-responses-api-hub\n",
      "Using repo root: C:\\Users\\user\\Desktop\\OpenAI-responses-api-hub\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Ensure project root is on sys.path (same pattern as Notebook 01) ---\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # parent of notebooks/\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from utils.openai_client import get_response  # now this should work\n",
    "\n",
    "# Load environment variables from .env at project root\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "# Create an SDK client (relies on OPENAI_API_KEY)\n",
    "client = OpenAI()\n",
    "\n",
    "# Treat the repo root as \".\"\n",
    "REPO_ROOT = PROJECT_ROOT\n",
    "print(f\"Using repo root: {REPO_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e870a7-b59e-445a-be89-c87c57e948dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default model: gpt-4.1-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>notes</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>Fast + cheap general</td>\n",
       "      <td>fast</td>\n",
       "      <td>Good default for most text tasks with Response...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4.1</td>\n",
       "      <td>High quality general</td>\n",
       "      <td>quality</td>\n",
       "      <td>Better reasoning/writing; higher cost.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>Reasoning</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>Use when you care about multi-step reasoning.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-image-1</td>\n",
       "      <td>Images</td>\n",
       "      <td>image</td>\n",
       "      <td>Image generation via Responses.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_id                 label   category  \\\n",
       "0  gpt-4.1-mini  Fast + cheap general       fast   \n",
       "1       gpt-4.1  High quality general    quality   \n",
       "2       o4-mini             Reasoning  reasoning   \n",
       "3   gpt-image-1                Images      image   \n",
       "\n",
       "                                               notes  available  \n",
       "0  Good default for most text tasks with Response...       True  \n",
       "1             Better reasoning/writing; higher cost.       True  \n",
       "2      Use when you care about multi-step reasoning.       True  \n",
       "3                    Image generation via Responses.       True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.config import DEFAULT_MODEL\n",
    "from utils.models import list_recommended_models\n",
    "import pandas as pd\n",
    "\n",
    "models_info = list_recommended_models()\n",
    "\n",
    "df_models = (\n",
    "    pd.DataFrame.from_dict(models_info, orient=\"index\")\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"model_id\"})\n",
    ")\n",
    "\n",
    "print(\"Using default model:\", DEFAULT_MODEL)\n",
    "df_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2863b2a-87a0-4280-bdb8-e6f68b536073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for this notebook: gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "# üéö Per-notebook model preference (optional)\n",
    "\n",
    "from utils.models import choose_default_model\n",
    "\n",
    "# Choose one: \"fast\", \"quality\", \"reasoning\", or \"image\"\n",
    "PREFERENCE = \"fast\"\n",
    "\n",
    "MODEL_FOR_THIS_NOTEBOOK = choose_default_model(PREFERENCE)\n",
    "print(\"Model for this notebook:\", MODEL_FOR_THIS_NOTEBOOK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed90fe-7d77-4d4e-88ea-f0f4d861f707",
   "metadata": {},
   "source": [
    "## üîë Step 1: Load Your API Key from `.env`\n",
    "\n",
    "To keep your API key safe, we don‚Äôt paste it into the notebook. Instead, we save it in a hidden `.env` file and load it from there.\n",
    "\n",
    "Think of the `.env` file like a secret drawer. We‚Äôre just opening the drawer and grabbing the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41810e2b-616b-401b-a9f5-c26d2818025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env at: C:\\Users\\user\\Desktop\\OpenAI-responses-api-hub\\.env\n",
      "API key loaded! ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Use PROJECT_ROOT from the setup cell\n",
    "env_path = os.path.join(PROJECT_ROOT, \".env\")\n",
    "print(\"Looking for .env at:\", env_path)\n",
    "\n",
    "load_dotenv(env_path)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API key loaded! ‚úÖ\" if api_key else \"‚ùå No API key found. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e2536-82f2-4ebc-a12c-0d4e20893f09",
   "metadata": {},
   "source": [
    "## üì° Step 2: Set Up the API Call\n",
    "\n",
    "Now we‚Äôre going to set up the request to OpenAI's **Responses API**.\n",
    "\n",
    "This is like writing a letter:\n",
    "- We need the **address** (the API URL) üì´  \n",
    "- We need to include our **ID card** (API key in the headers) ü™™  \n",
    "- And we need to say what we want to ask (the payload) ‚úçÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac37eb8-f080-4284-8b62-25996bdd3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Request setup complete!\n"
     ]
    }
   ],
   "source": [
    "# üì¨ Step 2: Set up the HTTP request to the Responses API\n",
    "\n",
    "import requests\n",
    "\n",
    "# Responses API endpoint\n",
    "url = \"https://api.openai.com/v1/responses\"\n",
    "\n",
    "# Headers include your API key and content type\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Request setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67561144-ca3a-4355-b52f-90a06c682e80",
   "metadata": {},
   "source": [
    "## ‚úâÔ∏è Step 3: Send a Message to the Chatbot\n",
    "\n",
    "Now that we have everything ready, let's send our first message!\n",
    "\n",
    "This is like putting our question in an envelope and mailing it to OpenAI's model.  \n",
    "We'll ask something simple and fun just to test things out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b77c48-1462-4769-89be-0c31fa1094c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request with model: gpt-4.1-mini\n",
      "HTTP status code: 200\n"
     ]
    }
   ],
   "source": [
    "# üíå Step 3: Send a message to the chatbot\n",
    "\n",
    "# The message we want to send to the model\n",
    "prompt = \"Hi there! Can you explain what a chatbot is like I'm 5 years old?\"\n",
    "\n",
    "# Payload = which model + what we want it to do\n",
    "payload = {\n",
    "    \"model\": MODEL_FOR_THIS_NOTEBOOK,  # comes from our model preference cell\n",
    "    \"input\": prompt,\n",
    "}\n",
    "\n",
    "print(\"Sending request with model:\", payload[\"model\"])\n",
    "\n",
    "# Send the request to the Responses API\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "print(\"HTTP status code:\", response.status_code)\n",
    "\n",
    "# Parse the JSON reply\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca983b8d-a76c-4f19-82a0-53903722074f",
   "metadata": {},
   "source": [
    "## üó£Ô∏è Step 4: Show the Chatbot's Response\n",
    "\n",
    "Now we‚Äôll extract just the AI's reply from the big JSON package.\n",
    "\n",
    "It‚Äôs like opening the letter the chatbot sent back and reading the actual message. üì©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649e4fe9-e6b7-4c88-86ea-88da4037f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Chatbot says:\n",
      "\n",
      "Hi! Sure! A chatbot is like a friendly robot you can talk to on a computer or phone. When you ask it questions or say something, it talks back to you and helps you, kind of like a pretend friend who knows lots of things!\n"
     ]
    }
   ],
   "source": [
    "# üì® Step 4: Show the chatbot's response\n",
    "\n",
    "try:\n",
    "    # Follow the Responses API JSON structure to get the text\n",
    "    output_text = response_json[\"output\"][0][\"content\"][0][\"text\"]\n",
    "    print(\"ü§ñ Chatbot says:\\n\")\n",
    "    print(output_text)\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Something went wrong while reading the response:\", e)\n",
    "    print(\"\\nRaw JSON for debugging:\")\n",
    "    print(response_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (,venv OpenAI Resonses Hub)",
   "language": "python",
   "name": "openai-responses-hub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
